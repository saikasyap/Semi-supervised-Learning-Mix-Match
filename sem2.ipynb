{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformTwice:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        out1 = self.transform(inp)\n",
    "        out2 = self.transform(inp)\n",
    "        return out1, out2\n",
    "\n",
    "def get_cifar10(root, n_labeled,\n",
    "                 transform_train=None, transform_val=None,\n",
    "                 download=True):\n",
    "\n",
    "    base_dataset = torchvision.datasets.CIFAR10(root, train=True, download=download)\n",
    "    train_labeled_idxs, train_unlabeled_idxs, val_idxs = train_val_split(base_dataset.targets, int(n_labeled/10))\n",
    "\n",
    "    train_labeled_dataset = CIFAR10_labeled(root, train_labeled_idxs, train=True, transform=transform_train)\n",
    "    train_unlabeled_dataset = CIFAR10_unlabeled(root, train_unlabeled_idxs, train=True, transform=TransformTwice(transform_train))\n",
    "    val_dataset = CIFAR10_labeled(root, val_idxs, train=True, transform=transform_val, download=True)\n",
    "    test_dataset = CIFAR10_labeled(root, train=False, transform=transform_val, download=True)\n",
    "\n",
    "    print (f\"#Labeled: {len(train_labeled_idxs)} #Unlabeled: {len(train_unlabeled_idxs)} #Val: {len(val_idxs)}\")\n",
    "    return train_labeled_dataset, train_unlabeled_dataset, val_dataset, test_dataset\n",
    "    \n",
    "\n",
    "def train_val_split(labels, n_labeled_per_class):\n",
    "    labels = np.array(labels)\n",
    "    train_labeled_idxs = []\n",
    "    train_unlabeled_idxs = []\n",
    "    val_idxs = []\n",
    "\n",
    "    for i in range(10):\n",
    "        idxs = np.where(labels == i)[0]\n",
    "        np.random.shuffle(idxs)\n",
    "        train_labeled_idxs.extend(idxs[:n_labeled_per_class])\n",
    "        train_unlabeled_idxs.extend(idxs[n_labeled_per_class:-500])\n",
    "        val_idxs.extend(idxs[-500:])\n",
    "    np.random.shuffle(train_labeled_idxs)\n",
    "    np.random.shuffle(train_unlabeled_idxs)\n",
    "    np.random.shuffle(val_idxs)\n",
    "\n",
    "    return train_labeled_idxs, train_unlabeled_idxs, val_idxs\n",
    "\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465) # equals np.mean(train_set.train_data, axis=(0,1,2))/255\n",
    "cifar10_std = (0.2471, 0.2435, 0.2616) # equals np.std(train_set.train_data, axis=(0,1,2))/255\n",
    "\n",
    "def normalise(x, mean=cifar10_mean, std=cifar10_std):\n",
    "    x, mean, std = [np.array(a, np.float32) for a in (x, mean, std)]\n",
    "    x -= mean*255\n",
    "    x *= 1.0/(255*std)\n",
    "    return x\n",
    "\n",
    "def transpose(x, source='NHWC', target='NCHW'):\n",
    "    return x.transpose([source.index(d) for d in target]) \n",
    "\n",
    "def pad(x, border=4):\n",
    "    return np.pad(x, [(0, 0), (border, border), (border, border)], mode='reflect')\n",
    "\n",
    "class RandomPadandCrop(object):\n",
    "    \"\"\"Crop randomly the image.\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = pad(x, 4)\n",
    "\n",
    "        h, w = x.shape[1:]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        x = x[:, top: top + new_h, left: left + new_w]\n",
    "\n",
    "        return x\n",
    "\n",
    "class RandomFlip(object):\n",
    "    \"\"\"Flip randomly the image.\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        if np.random.rand() < 0.5:\n",
    "            x = x[:, :, ::-1]\n",
    "\n",
    "        return x.copy()\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    \"\"\"Add gaussian noise to the image.\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        c, h, w = x.shape\n",
    "        x += np.random.randn(c, h, w) * 0.15\n",
    "        return x\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Transform the image to tensor.\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        x = torch.from_numpy(x)\n",
    "        return x\n",
    "\n",
    "class CIFAR10_labeled(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root, indexs=None, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        super(CIFAR10_labeled, self).__init__(root, train=train,\n",
    "                 transform=transform, target_transform=target_transform,\n",
    "                 download=download)\n",
    "        if indexs is not None:\n",
    "            self.data = self.data[indexs]\n",
    "            self.targets = np.array(self.targets)[indexs]\n",
    "        self.data = transpose(normalise(self.data))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "\n",
    "class CIFAR10_unlabeled(CIFAR10_labeled):\n",
    "\n",
    "    def __init__(self, root, indexs, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        super(CIFAR10_unlabeled, self).__init__(root, indexs, train=train,\n",
    "                 transform=transform, target_transform=target_transform,\n",
    "                 download=download)\n",
    "        self.targets = np.array([-1 for i in range(len(self.targets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from efficientnet_pytorch import EfficientNet as effNet\n",
    "\n",
    "class Conv2dSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]]*2\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n",
    "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "def relu_fn(x):\n",
    "    \"\"\" Swish activation function \"\"\"\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes, version = 'b0'):\n",
    "        super(EfficientNet, self).__init__()\n",
    "\n",
    "        # load pretrained EfficientNet B3\n",
    "        self.model_ft = effNet.from_pretrained(f'efficientnet-{version}')\n",
    "\n",
    "        for child in self.model_ft.children():\n",
    "\n",
    "          for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # re-init last conv layer and last fc layer to fit with dataset\n",
    "        in_channels = self.model_ft._conv_head.in_channels\n",
    "        out_channels = self.model_ft._conv_head.out_channels\n",
    "        num_ftrs = self.model_ft._fc.in_features\n",
    "\n",
    "        self.model_ft._conv_head = Conv2dSamePadding(in_channels, out_channels, kernel_size=(1,1), stride=(1,1), bias=False)\n",
    "        self.model_ft._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=0.010000000000000009, eps = 0.001)\n",
    "        self.model_ft._fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model_ft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_augmenter():\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(px=(0, 16)),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.GaussianBlur(sigma=(0, 3.0))\n",
    "    ])\n",
    "    def augment(images):\n",
    "        return seq.augment(images.transpose(0, 2, 3, 1)).transpose(0, 2, 3, 1)\n",
    "    return augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(x, T):\n",
    "    temp = x**(1/T)\n",
    "    return temp / temp.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(x1, x2, y1, y2, alpha):\n",
    "    beta = np.random.beta(alpha, -alpha)\n",
    "    x = beta * x1 + (1 - beta) * x2\n",
    "    y = beta * y1 + (1 - beta) * y2\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixmatch(x, y, u, model, augment_fn, T=0.5, K=2, alpha=0.75):\n",
    "    xb = augment_fn(x)\n",
    "    ub = [augment_fn(u) for _ in range(K)]\n",
    "    qb = sharpen(sum(map(lambda i: model(i), ub)) / K, T)\n",
    "    Ux = np.concatenate(ub, axis=0)\n",
    "    Uy = np.concatenate([qb for _ in range(K)], axis=0)\n",
    "    indices = np.random.shuffle(np.arange(len(xb) + len(Ux)))\n",
    "    Wx = np.concatenate([Ux, xb], axis=0)[indices]\n",
    "    Wy = np.concatenate([qb, y], axis=0)[indices]\n",
    "    X, p = mixup(xb, Wx[:len(xb)], y, Wy[:len(xb)], alpha)\n",
    "    U, q = mixup(Ux, Wx[len(xb):], Uy, Wy[len(xb):], alpha)\n",
    "    return X, U, p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixMatchLoss(torch.nn.Module):\n",
    "    def __init__(self, lambda_u=100):\n",
    "        self.lambda_u = lambda_u\n",
    "        self.xent = torch.nn.CrossEntropyLoss()\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        super(MixMatchLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, X, U, p, q, model):\n",
    "        X_ = np.concatenate([X, U], axis=1)\n",
    "        preds = model(X_)\n",
    "        return self.xent(preds[:len(p)], p) + \\\n",
    "                                    self.lambda_u * self.mse(preds[len(p):], q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return torch.nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                           bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
    "        torch.nn.init.constant(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.constant(m.weight, 1)\n",
    "        torch.nn.init.constant(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_generator(x, y=None, batch_size=32, shuffle=True):\n",
    "    i = 0\n",
    "    all_indices = np.random.shuffle(np.arange(len(x))) if shuffle else \\\n",
    "                                                               np.arange(len(x))\n",
    "    while(True):\n",
    "        indices = all_indices[i:i+batch_size]\n",
    "        if y is not None:\n",
    "            yield x[indices], y[indices]\n",
    "        yield x[indices]\n",
    "        i = (i + batch_size) % len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixmatch_wrapper(x, y, u, model, batch_size=32):\n",
    "    augment_fn = get_augmenter()\n",
    "    train_generator = basic_generator(x, y, batch_size)\n",
    "    unlabeled_generator = basic_generator(u, batch_size=batch_size)\n",
    "    while(True):\n",
    "        xi, yi = next(train_generator)\n",
    "        ui = next(unlabeled_generator)\n",
    "        yield mixmatch(xi, yi, ui, model, augment_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(*args, device='cuda'):\n",
    "    convert_fn = lambda x: torch.from_numpy(x).to(device)\n",
    "    return list(map(convert_fn, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_gen, test_iters):\n",
    "    acc = []\n",
    "    for i, (x, y) in enumerate(test_gen):\n",
    "        x = to_torch(x)\n",
    "        pred = model(x).to('cpu').argmax(axis=1)\n",
    "        acc.append(np.mean(pred == y.argmax(axis=1)))\n",
    "        if i == test_iters:\n",
    "            break\n",
    "    print('Accuracy was : {}'.format(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss_history):\n",
    "    print('Average loss in last epoch was : {}'.format(np.mean(loss_history)))\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, iter, train_iters):\n",
    "    torch.save(model.state_dict(), 'model_{}.pth'.format(train_iters // iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, train_gen, test_gen, epochs, train_iters, test_iters, device):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = MixMatchLoss()\n",
    "    loss_history = []\n",
    "    for i, (x, u, p, q) in enumerate(train_gen):\n",
    "        if i % train_iters == 0:\n",
    "            loss_history = report(loss_history)\n",
    "            test(model, test_gen, test_iters)\n",
    "            save(model, i, train_iters)\n",
    "            if i // train_iters == epochs:\n",
    "                return\n",
    "        else:\n",
    "            optim.zero_grad()\n",
    "            x, u, p, q = to_torch(x, u, p, q, device=device)\n",
    "            loss = loss_fn(x, u, p, q, model)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            loss_history.append(loss.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    training_amount = 250\n",
    "    training_u_amount = 40000\n",
    "    validation_amount = 500\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=None)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=None)\n",
    "\n",
    "    X_train = np.array(trainset.data)\n",
    "    y_train = np.array(trainset.targets)\n",
    "\n",
    "    X_test = np.array(testset.data)\n",
    "    y_test = np.array(testset.targets)\n",
    "\n",
    "    # Train set / Validation set split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_amount, random_state=1,\n",
    "                                                              shuffle=True, stratify=y_train)\n",
    "\n",
    "    # Train unsupervised / Train supervised split\n",
    "    # Train set / Validation set split\n",
    "    X_train, X_u_train, y_train, y_u_train = train_test_split(X_train, y_train, test_size=training_u_amount, random_state=1,\n",
    "                                                              shuffle=True, stratify=y_train)\n",
    "\n",
    "    X_remain, X_train, y_remain, y_train = train_test_split(X_train, y_train, test_size=training_amount, random_state=1,\n",
    "                                                              shuffle=True, stratify=y_train)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # model = Wide_ResNet(28, 10, 0.3, 10).cuda()\n",
    "    model = Wide_ResNet(10).cuda()\n",
    "\n",
    "    y_train = torch.tensor(y_train).cuda()\n",
    "    y_train = torch.nn.functional.one_hot(y_train).float()\n",
    "\n",
    "    train_generator = mixmatch_wrapper(X_train, y_train, X_u_train, model, 32)\n",
    "    test_generator = basic_generator(X_remain, y_remain, 32)\n",
    "    # run(model, train_generator, test_generator, 100, 20, )\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=.00001)\n",
    "    loss_fn = MixMatchLoss()\n",
    "    final_loss = 0\n",
    "    count = 0\n",
    "    for i, (x, u, p, q) in enumerate(train_generator):\n",
    "        model.train()\n",
    "        loss = loss_fn(x, u, p, q, model)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        final_loss += loss.item()\n",
    "        count += 1\n",
    "        if i%100 == 0:\n",
    "            print(f\"loss is {final_loss/count}\")\n",
    "            test(model, test_generator, 50)\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
